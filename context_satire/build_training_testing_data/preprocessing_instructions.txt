1) Generate ranked documents using data_pipeline
2) Run make_docs.py to generate document folders
3) Run Stanford Core NLP on 4 folders: train/test docs, train/test heads:

python ../PreSumm/src_preprocess/preprocess.py -mode tokenize -raw_path RAW_PATH -save_path TOKENIZED_PATH
e.g. python  ../PreSumm/src_preprocess/preprocess.py -mode tokenize -raw_path split_docs_train -save_path train_docs -log_file out.log

4) Run make_simple.json
5) Convert to pytorch files

python  ../PreSumm/src_preprocess/preprocess.py -mode format_to_bert_zach -raw_path JSON_PATH -save_path BERT_DATA_PATH  -lower -n_cpus 1 -log_file preprocess.log
python  ../PreSumm/src_preprocess/preprocess.py -mode format_to_bert_zach -raw_path processed_docs -save_path . -lower -n_cpus 1 -log_file preprocess.log
